# Sales Analytics Demo Dataset

A comprehensive synthetic dataset generator for building sales analytics demos in Snowflake or Databricks.

## ğŸ“ Project Structure

```
synthetic_data_sales/
â”œâ”€â”€ README.md                    # This file - project overview
â”œâ”€â”€ docs/                        # Documentation files
â”‚   â”œâ”€â”€ complete_readme.md       # Complete setup guide
â”‚   â”œâ”€â”€ schema_documentation.md  # Detailed schema documentation
â”‚   â”œâ”€â”€ QUICK_START_SNOWFLAKE.md # Quick start guide for Snowflake
â”‚   â”œâ”€â”€ SNOWFLAKE_LOADING_GUIDE.md # Detailed Snowflake loading guide
â”‚   â”œâ”€â”€ databricks_upload_readme.md # Databricks setup guide
â”‚   â”œâ”€â”€ quick_reference.md       # Quick reference guide
â”‚   â””â”€â”€ sales_rep_questions.md   # Sales rep Q&A
â”œâ”€â”€ scripts/                     # Python scripts
â”‚   â”œâ”€â”€ sales_data_generator_part1.py  # Generator part 1 (16 tables)
â”‚   â”œâ”€â”€ sales_data_generator_part2.py  # Generator part 2 (10 tables)
â”‚   â”œâ”€â”€ sales_data_generator_part3.py  # Generator part 3 (21 tables)
â”‚   â”œâ”€â”€ sales_data_generator_part4.py  # Generator part 4 (15 tables)
â”‚   â”œâ”€â”€ load_to_snowflake.py    # Snowflake data loader (loads all tables)
â”‚   â”œâ”€â”€ load_specific_tables.py  # Quick test script (loads specific tables)
â”‚   â”œâ”€â”€ verify_dataset.py        # Dataset verification script
â”‚   â”œâ”€â”€ databricks_unity_catalog_loader.py # Databricks loader
â”‚   â””â”€â”€ users_databricks_setup.py # Databricks user setup
â”œâ”€â”€ sql/                         # SQL scripts
â”‚   â”œâ”€â”€ snowflake_ddl_script.sql # Snowflake DDL (creates all 62 tables)
â”‚   â””â”€â”€ security_policies_snowflake.sql # Security policies
â”œâ”€â”€ diagrams/                    # Schema diagrams
â”‚   â”œâ”€â”€ schema_overview.png      # Overview diagram
â”‚   â”œâ”€â”€ entity_relationship.png  # ER diagram
â”‚   â”œâ”€â”€ cross_schema_relationships.png # Cross-schema diagram
â”‚   â”œâ”€â”€ schema_overview.mmd      # Mermaid source files
â”‚   â”œâ”€â”€ entity_relationship.mmd
â”‚   â””â”€â”€ cross_schema_relationships.mmd
â”œâ”€â”€ sales_analytics_data/        # Generated CSV files (output)
â”‚   â”œâ”€â”€ sales_data/              # 17 tables
â”‚   â”œâ”€â”€ usage_data/              # 11 tables
â”‚   â”œâ”€â”€ marketing_data/           # 13 tables
â”‚   â”œâ”€â”€ support_data/            # 12 tables
â”‚   â””â”€â”€ operational_data/        # 9 tables
â”œâ”€â”€ archive/                     # Old/unused files
â””â”€â”€ venv/                        # Python virtual environment
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8 or higher
- Snowflake account (for loading data)
- (Optional) Databricks account (for Databricks loading)

### Setup

1. **Clone or download this repository**

2. **Create and activate a virtual environment:**
   ```bash
   python3 -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Generate the dataset:**
   ```bash
   python3 scripts/sales_data_generator_part1.py
   python3 scripts/sales_data_generator_part2.py
   python3 scripts/sales_data_generator_part3.py
   python3 scripts/sales_data_generator_part4.py
   ```

5. **Load into Snowflake:**
   - Set environment variables:
     ```bash
     export SNOWFLAKE_USER="your_username"
     export SNOWFLAKE_PASSWORD="your_password"
     export SNOWFLAKE_ACCOUNT="your_account"
     export SNOWFLAKE_WAREHOUSE="your_warehouse"
     ```
   - See `docs/QUICK_START_SNOWFLAKE.md` for detailed instructions
   - Run: `python3 scripts/load_to_snowflake.py`

## ğŸš€ Quick Start (Legacy)

### 1. Generate Data

```bash
# Run all four generator scripts
python3 scripts/sales_data_generator_part1.py
python3 scripts/sales_data_generator_part2.py
python3 scripts/sales_data_generator_part3.py
python3 scripts/sales_data_generator_part4.py

# Verify generation
python3 scripts/verify_dataset.py
```

### 2. Load into Snowflake

See `docs/QUICK_START_SNOWFLAKE.md` for quick instructions, or `docs/SNOWFLAKE_LOADING_GUIDE.md` for detailed guide.

### 3. Load into Databricks

See `docs/databricks_upload_readme.md` for instructions.

## ğŸ“Š Dataset Overview

- **62 tables** across 5 schemas
- **~1.5 million records** of realistic synthetic data
- **Sales & Customer Data** (17 tables): Customers, products, opportunities, deals, contracts
- **Product Usage & Telemetry** (11 tables): Usage metrics, feature adoption, API calls
- **Marketing Data** (13 tables): Campaigns, leads, engagement, attribution
- **Support & Service** (12 tables): Tickets, resolutions, CSAT, SLA tracking
- **Operational Data** (9 tables): Health scores, invoices, payments, renewals

## ğŸ“š Documentation

- **Complete Guide**: `docs/complete_readme.md`
- **Schema Documentation**: `docs/schema_documentation.md`
- **Snowflake Setup**: `docs/SNOWFLAKE_LOADING_GUIDE.md`
- **Quick Start**: `docs/QUICK_START_SNOWFLAKE.md`
- **Diagrams**: `diagrams/` folder

## ğŸ”§ Requirements

- Python 3.8+
- pandas, numpy
- snowflake-connector-python (for Snowflake loading)
- Snowflake account OR Databricks workspace

## ğŸ“ Usage

### Generate Data
```bash
python3 scripts/sales_data_generator_part1.py
python3 scripts/sales_data_generator_part2.py
python3 scripts/sales_data_generator_part3.py
python3 scripts/sales_data_generator_part4.py
```

### Load to Snowflake
```bash
# 1. Run DDL script in Snowflake Web UI (sql/snowflake_ddl_script.sql)
# 2. Set environment variables (see .env.example)
# 3. Run loader
python3 scripts/load_to_snowflake.py

# Optional: Configure row-level security (after loading data)
# Run sql/security_policies_snowflake.sql in Snowflake Web UI
```

### Verify Dataset
```bash
python3 scripts/verify_dataset.py
```

## ğŸ—‚ï¸ File Organization

- **docs/**: All documentation and guides
- **scripts/**: All Python scripts (generators, loaders, utilities)
- **sql/**: SQL DDL and security scripts
- **diagrams/**: Schema diagrams and visualizations
- **sales_analytics_data/**: Generated CSV output (gitignored)
- **archive/**: Old/unused files kept for reference

## ğŸ“„ License

This synthetic dataset is provided for demo and educational purposes.

---

For detailed information, see the documentation in the `docs/` folder.

